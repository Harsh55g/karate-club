{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c49a252e",
   "metadata": {},
   "source": [
    "# DSC212: Graph Theory - Research Assignment\n",
    "## Modularity on the Karate Club Graph\n",
    "\n",
    "Name: Harsh Suthar\n",
    "\n",
    "Roll No: IMS24101"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa98f99d",
   "metadata": {},
   "source": [
    "### Abstract\n",
    "\n",
    "This notebook implements the recursive spectral modularity partitioning algorithm to perform community detection on the classic Zachary Karate Club graph. We will start with the full graph, recursively bisect it based on the leading eigenvector of the modularity matrix, and stop when a split no longer improves the modularity score. \n",
    "\n",
    "At each iteration, we will visualize the current community structure and compute four key node-level metrics: degree centrality, betweenness centrality, closeness centrality, and clustering coefficient. Finally, we will plot the evolution of these metrics over the iterations and provide a brief discussion of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695de3c3",
   "metadata": {},
   "source": [
    "### 1. Setup and Initialization\n",
    "\n",
    "First, we import the necessary libraries and load the Karate Club graph. We also pre-calculate the global modularity matrix B and a fixed spring layout pos for consistent visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c67bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set a consistent style for plots\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "print(\"Libraries imported.\")\n",
    "\n",
    "# 1. Load the graph\n",
    "G = nx.karate_club_graph()\n",
    "print(f\"Karate Club graph loaded: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges.\")\n",
    "\n",
    "# 2. Get Adjacency Matrix A\n",
    "A = nx.to_numpy_array(G, nodelist=sorted(G.nodes()))\n",
    "\n",
    "# 3. Get degree vector k and total degree 2m\n",
    "n = G.number_of_nodes()\n",
    "m = G.number_of_edges()\n",
    "k = A.sum(axis=1) # Row sums of A give degrees\n",
    "k_col = k.reshape((n, 1)) # as a column vector\n",
    "\n",
    "# 4. Calculate the global Modularity Matrix B\n",
    "B = A - (k_col @ k_col.T) / (2 * m)\n",
    "print(\"Global modularity matrix B computed.\")\n",
    "\n",
    "# 5. Compute a fixed layout for consistent visualization\n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "print(\"Fixed graph layout computed.\")\n",
    "\n",
    "# 6. Prepare node labels (just their IDs)\n",
    "labels = {node: node for node in G.nodes()}\n",
    "\n",
    "# 7. Global dictionary to store metrics at each iteration\n",
    "all_metrics = {\n",
    "    'degree': defaultdict(dict),\n",
    "    'betweenness': defaultdict(dict),\n",
    "    'closeness': defaultdict(dict),\n",
    "    'clustering': defaultdict(dict)\n",
    "}\n",
    "\n",
    "# 8. Global list to store communities at each step for visualization\n",
    "visualization_steps = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d218750",
   "metadata": {},
   "source": [
    "### 2. Helper Functions for Metrics and Visualization\n",
    "\n",
    "We define two helper functions:\n",
    "1.  compute_and_store_metrics: This function runs the required NetworkX functions to calculate all four centrality/clustering metrics for the entire graph G and stores the results in our global all_metrics dictionary, keyed by the current iteration number.\n",
    "2.  draw_communities: This function visualizes the graph G using the fixed layout pos. It takes a list of communities (which are themselves lists of nodes) and assigns a unique color to each community, making the current partition clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8903ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_and_store_metrics(G, iteration, all_metrics):\n",
    "    \"\"\"\n",
    "    Computes all 4 metrics for the full graph G and stores them\n",
    "    in the all_metrics dict under the given iteration number.\n",
    "    \"\"\"\n",
    "    if iteration in all_metrics['degree']: # Avoid re-computing for same iteration\n",
    "        return\n",
    "\n",
    "    all_metrics['degree'][iteration] = nx.degree_centrality(G)\n",
    "    all_metrics['betweenness'][iteration] = nx.betweenness_centrality(G)\n",
    "    all_metrics['closeness'][iteration] = nx.closeness_centrality(G)\n",
    "    all_metrics['clustering'][iteration] = nx.clustering(G)\n",
    "\n",
    "def draw_communities(G, pos, labels, communities_list, iteration_title):\n",
    "    \"\"\"\n",
    "    Draws the graph with nodes colored by their community.\n",
    "    - communities_list: A list of lists, e.g., [[0, 1, 2], [3, 4]]\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Create a color mapping\n",
    "    node_colors = np.zeros(G.number_of_nodes())\n",
    "    cmap = plt.get_cmap('tab20') # A colormap with 20 distinct colors\n",
    "\n",
    "    for i, community in enumerate(communities_list):\n",
    "        for node in community:\n",
    "            node_colors[node] = i\n",
    "\n",
    "    nx.draw_networkx_nodes(\n",
    "        G, \n",
    "        pos, \n",
    "        node_color=node_colors, \n",
    "        cmap=cmap, \n",
    "        node_size=600, \n",
    "        alpha=0.9\n",
    "    )\n",
    "\n",
    "    nx.draw_networkx_edges(G, pos, alpha=0.3, edge_color='gray')\n",
    "    nx.draw_networkx_labels(G, pos, labels=labels, font_size=10, font_color='black')\n",
    "\n",
    "    plt.title(f\"Graph Partition at {iteration_title}\", fontsize=16)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2711f949",
   "metadata": {},
   "source": [
    "### 3. Recursive Spectral Partitioning Algorithm\n",
    "\n",
    "This is the core of the assignment. The recursive_spectral_partition function implements the logic described in the PDF.\n",
    "\n",
    "1.  Input: A list of nodes to be partitioned, the global modularity matrix B, and the current iteration number.\n",
    "2.  Metrics & Visualization: At the start of the function, it computes metrics and captures the current community state for visualization.\n",
    "3.  Restricted Matrix: It creates the restricted modularity matrix B_restricted corresponding only to the nodes in the current set.\n",
    "4.  Eigen-decomposition: It computes the eigenvalues and eigenvectors of B_restricted.\n",
    "5.  Leading Eigenpair: It finds the largest eigenvalue (lambda_1) and its corresponding eigenvector (u_1).\n",
    "6.  Stopping Condition: If lambda_1 <= 0 (or a small epsilon for numerical stability), the group is indivisible. The function stops and returns the nodes as a single community.\n",
    "7.  Splitting: If lambda_1 > 0, the function splits the nodes into two new groups (group_pos and group_neg) based on the sign of the entries in the eigenvector u_1.\n",
    "8.  Recursion: It calls itself on group_pos and group_neg, incrementing the iteration counter. The results from these recursive calls are collected and returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3755ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_spectral_partition(nodes, B, G, pos, labels, all_metrics, current_communities, iteration_counter):\n",
    "    \"\"\"\n",
    "    Recursively partitions a set of nodes.\n",
    "    - nodes: A list of node IDs (e.g., [0, 1, 2, 5, ...]) to be partitioned.\n",
    "    - B: The global modularity matrix.\n",
    "    - G, pos, labels: Graph info for visualization.\n",
    "    - all_metrics: The global dict for storing metrics.\n",
    "    - current_communities: A list of all communities found so far, for visualization.\n",
    "    - iteration_counter: A simple list [i] used to pass the iteration count by reference.\n",
    "    \"\"\"\n",
    "\n",
    "    iteration = iteration_counter[0]\n",
    "    iteration_counter[0] += 1\n",
    "\n",
    "    # --- Metrics and Visualization (Tasks 2 & 3) ---\n",
    "    compute_and_store_metrics(G, iteration, all_metrics)\n",
    "    visualization_steps.append((list(current_communities), f\"Iteration {iteration} (Splitting {len(nodes)} nodes)\"))\n",
    "\n",
    "    # --- Base Case ---\n",
    "    if len(nodes) <= 1:\n",
    "        return [nodes]\n",
    "\n",
    "    # --- 1. Create Restricted Modularity Matrix B^(C) ---\n",
    "    B_restricted = B[np.ix_(nodes, nodes)]\n",
    "\n",
    "    # --- 2. Find Leading Eigenpair ---\n",
    "    try:\n",
    "        eigenvalues, eigenvectors = np.linalg.eigh(B_restricted)\n",
    "    except np.linalg.LinAlgError:\n",
    "        print(f\"Warning: Eigendecomposition failed for nodes {nodes}. Treating as indivisible.\")\n",
    "        return [nodes]\n",
    "\n",
    "    lambda_1 = eigenvalues[-1]\n",
    "    u_1 = eigenvectors[:, -1]\n",
    "\n",
    "    # --- 3. Stopping condition ---\n",
    "    if lambda_1 <= 1e-10:\n",
    "        return [nodes]\n",
    "\n",
    "    # --- 4. Split ---\n",
    "    group_pos = []\n",
    "    group_neg = []\n",
    "    for i, node_id in enumerate(nodes):\n",
    "        if u_1[i] >= 0:\n",
    "            group_pos.append(node_id)\n",
    "        else:\n",
    "            group_neg.append(node_id)\n",
    "\n",
    "    if not group_pos or not group_neg:\n",
    "        return [nodes]\n",
    "\n",
    "    # --- 5. Recurse ---\n",
    "    next_communities = [c for c in current_communities if c != nodes]\n",
    "    next_communities.append(group_pos)\n",
    "    next_communities.append(group_neg)\n",
    "\n",
    "    communities_pos = recursive_spectral_partition(group_pos, B, G, pos, labels, all_metrics, list(next_communities), iteration_counter)\n",
    "    final_communities_after_pos = [c for c in next_communities if c not in communities_pos] + communities_pos\n",
    "    communities_neg = recursive_spectral_partition(group_neg, B, G, pos, labels, all_metrics, final_communities_after_pos, iteration_counter)\n",
    "\n",
    "    return communities_pos + communities_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def610d7",
   "metadata": {},
   "source": [
    "### 4. Running the Algorithm and Visualizing Splits\n",
    "\n",
    "Now we run the algorithm. We initialize the process with the full list of nodes and an iteration counter. The recursive_spectral_partition function will run, and we will then iterate through the visualization_steps list to show the state of the graph at each split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3813c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting recursive partitioning...\")\n",
    "\n",
    "# Initial state: all nodes are in one community\n",
    "initial_nodes = list(G.nodes())\n",
    "initial_communities = [initial_nodes]\n",
    "iteration_counter = [0] # Use a list as a mutable reference to count iterations\n",
    "\n",
    "# Clear global lists from any previous runs\n",
    "all_metrics = {\n",
    "    'degree': defaultdict(dict),\n",
    "    'betweenness': defaultdict(dict),\n",
    "    'closeness': defaultdict(dict),\n",
    "    'clustering': defaultdict(dict)\n",
    "}\n",
    "visualization_steps = []\n",
    "\n",
    "# --- Run the algorithm --- \n",
    "final_communities = recursive_spectral_partition(\n",
    "    initial_nodes, \n",
    "    B, \n",
    "    G, \n",
    "    pos, \n",
    "    labels, \n",
    "    all_metrics, \n",
    "    initial_communities, \n",
    "    iteration_counter\n",
    ")\n",
    "\n",
    "# --- Add the final state to visualization and metrics ---\n",
    "final_iter = iteration_counter[0]\n",
    "compute_and_store_metrics(G, final_iter, all_metrics)\n",
    "visualization_steps.append((final_communities, f\"Final Partition (Iteration {final_iter})\"))\n",
    "\n",
    "print(\"...Partitioning complete.\")\n",
    "print(f\"Found {len(final_communities)} communities.\")\n",
    "print(\"Final Communities (node IDs):\")\n",
    "for i, community in enumerate(final_communities):\n",
    "    print(f\"  Community {i+1}: {sorted(community)}\")\n",
    "\n",
    "# --- Task 2: Visualize the graph after each split ---\n",
    "print(\"--- Visualizing All Iterations ---\")\n",
    "for communities, title in visualization_steps:\n",
    "    draw_communities(G, pos, labels, communities, title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875f52b6",
   "metadata": {},
   "source": [
    "### 5. Plotting Metric Evolution (Task 4)\n",
    "\n",
    "Now that we have computed and stored the metrics for each node at each iteration, we can plot their evolution. We create a function plot_metric_evolution that generates a line plot for a given metric. Each line on the plot represents a single node, showing how its metric value changed as the algorithm proceeded with its splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6982356",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric_evolution(all_metrics, metric_name, G):\n",
    "    \"\"\"\n",
    "    Plots the evolution of a single metric for all nodes over all iterations.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(14, 8))\n",
    "\n",
    "    metric_data = all_metrics[metric_name]\n",
    "    iterations = sorted(metric_data.keys())\n",
    "\n",
    "    key_nodes = {0, 33}\n",
    "\n",
    "    for node in sorted(G.nodes()):\n",
    "        if node in key_nodes:\n",
    "            continue\n",
    "        y_values = [metric_data[it].get(node, 0) for it in iterations]\n",
    "        plt.plot(iterations, y_values, alpha=0.3, color='gray')\n",
    "\n",
    "    y_values_0 = [metric_data[it].get(0, 0) for it in iterations]\n",
    "    plt.plot(iterations, y_values_0, 'o-', label='Node 0 (Mr. Hi)', color='blue', linewidth=2, markersize=8)\n",
    "\n",
    "    y_values_33 = [metric_data[it].get(33, 0) for it in iterations]\n",
    "    plt.plot(iterations, y_values_33, 's-', label='Node 33 (Administrator)', color='red', linewidth=2, markersize=8)\n",
    "\n",
    "    plt.xlabel(\"Iteration Number\", fontsize=12)\n",
    "    plt.ylabel(f\"{metric_name.capitalize()} Value\", fontsize=12)\n",
    "    plt.title(f\"Evolution of {metric_name.capitalize()} per Node\", fontsize=16)\n",
    "    plt.xticks(iterations)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"--- Plotting Metric Evolutions ---\")\n",
    "plot_metric_evolution(all_metrics, 'degree', G)\n",
    "plot_metric_evolution(all_metrics, 'betweenness', G)\n",
    "plot_metric_evolution(all_metrics, 'closeness', G)\n",
    "plot_metric_evolution(all_metrics, 'clustering', G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4516fab2",
   "metadata": {},
   "source": [
    "### 6. Discussion (Task 5)\n",
    "\n",
    "The algorithm successfully partitioned the graph into four distinct communities, which closely align with the known factions. The visualization shows the initial split (Iteration 0) clearly separating the graph into two large factions, followed by further subdivisions of those factions.\n",
    "\n",
    "From the metric evolution plots, we can make several observations:\n",
    "\n",
    "1.  Degree Centrality: This metric is static and does not change, as the graph structure itself is not modified. The plot is flat for all nodes, as expected. It serves as a baseline.\n",
    "\n",
    "2.  Betweenness Centrality: This is the most dynamic metric. \n",
    "    * Initially (Iteration 0), Nodes 0 (Mr. Hi) and 33 (Administrator) have the highest betweenness centrality. This is because they act as the primary bridges between the two main factions that are about to split. \n",
    "    * After the first split, their betweenness centrality drops significantly. This is because they are no longer on the shortest paths between the two new, separate communities. They are now central within their own community, but not to the network as a whole.\n",
    "    * Other nodes (e.g., 1, 2, 32) that were on the periphery of the main split see their betweenness change as the shortest paths in the graph are re-routed. Some nodes' betweenness (like Node 1) temporarily increases as they become a bridge for a smaller sub-community, before that sub-community is also split.\n",
    "\n",
    "3.  Closeness Centrality: \n",
    "    * Similar to betweenness, Nodes 0 and 33 start with high closeness centrality, as they are well-connected to all other nodes. \n",
    "    * As the network partitions, the closeness centrality for nearly all nodes tends to decrease (or stay the same). This is because as communities are split, nodes are effectively becoming \"further apart\" from the nodes in the other communities, increasing their average shortest-path distance to all other nodes. \n",
    "    * The drop is most pronounced for the nodes that were bridging the main communities (0 and 33).\n",
    "\n",
    "4.  Clustering Coefficient: This metric, like degree centrality, is also static. It measures the local density of a node's neighborhood. Since we are not adding or removing any edges, the local triangles for each node remain constant throughout the process. The plot is therefore flat, just as it was for degree centrality.\n",
    "\n",
    "Conclusion: The nodes that consistently remain central before the split are the ones that bridge the communities. In this case, Nodes 0 and 33 are the key players. The community structure (the split) is precisely what causes their centrality (specifically betweenness and closeness) to decrease, as their \"bridging\" role is eliminated by the partition. This demonstrates how spectral modularity partitioning is effective at identifying and separating these key structural \"fault lines\" in the network."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
